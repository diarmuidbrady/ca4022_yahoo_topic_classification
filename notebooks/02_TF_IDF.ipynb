{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ee38ba4-dc13-46b7-8f50-94f88b69dc52",
   "metadata": {},
   "source": [
    "# Yahoo Topic Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff719a6-166a-41bb-acf3-8be5d0f2409c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T10:38:08.745184Z",
     "iopub.status.busy": "2022-11-24T10:38:08.743460Z",
     "iopub.status.idle": "2022-11-24T10:38:09.328424Z",
     "shell.execute_reply": "2022-11-24T10:38:09.325422Z",
     "shell.execute_reply.started": "2022-11-24T10:38:08.744184Z"
    },
    "tags": []
   },
   "source": [
    "## Setting up Libraries and Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbb9a2b7-d4ec-4caf-bf1a-770986bfe332",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T08:18:32.166525Z",
     "iopub.status.busy": "2022-12-16T08:18:32.166525Z",
     "iopub.status.idle": "2022-12-16T08:18:34.968321Z",
     "shell.execute_reply": "2022-12-16T08:18:34.967551Z",
     "shell.execute_reply.started": "2022-12-16T08:18:32.166525Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import findspark\n",
    "import pyspark\n",
    "from pyspark import SparkFiles\n",
    "\n",
    "# Data Manipulation\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# ML\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LinearSVC, OneVsRest, LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4a745df-3b53-44d6-b49a-f3656dac14df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T08:18:34.971289Z",
     "iopub.status.busy": "2022-12-16T08:18:34.970818Z",
     "iopub.status.idle": "2022-12-16T08:18:45.814731Z",
     "shell.execute_reply": "2022-12-16T08:18:45.814731Z",
     "shell.execute_reply.started": "2022-12-16T08:18:34.971289Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "findspark.init()\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d591fd-51c5-46bc-987f-6ac8ca5360af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T15:12:38.695557Z",
     "iopub.status.busy": "2022-11-25T15:12:38.695557Z",
     "iopub.status.idle": "2022-11-25T15:12:42.365718Z",
     "shell.execute_reply": "2022-11-25T15:12:42.364754Z",
     "shell.execute_reply.started": "2022-11-25T15:12:38.695557Z"
    },
    "tags": []
   },
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f51b2065-0187-468d-8c89-4a1c8e990f2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T08:18:45.816695Z",
     "iopub.status.busy": "2022-12-16T08:18:45.815697Z",
     "iopub.status.idle": "2022-12-16T08:18:45.831696Z",
     "shell.execute_reply": "2022-12-16T08:18:45.830762Z",
     "shell.execute_reply.started": "2022-12-16T08:18:45.816695Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema_list = [\n",
    "    StructField('Label', StringType(), False), \n",
    "    StructField('Title', StringType(), True), \n",
    "    StructField('Content', StringType(), True),\n",
    "    StructField('Answer', StringType(), True),\n",
    "    StructField('Set', StringType(), True)\n",
    "]\n",
    "schema_df = StructType(fields=schema_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d88c51c-f25e-4c4e-98af-592fcf95e1ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T08:18:45.834696Z",
     "iopub.status.busy": "2022-12-16T08:18:45.833696Z",
     "iopub.status.idle": "2022-12-16T08:18:48.922406Z",
     "shell.execute_reply": "2022-12-16T08:18:48.921510Z",
     "shell.execute_reply.started": "2022-12-16T08:18:45.834696Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Data from reduced folders\n",
    "df = spark.read.csv(\"../data/reduced\", schema=schema_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15f0701-ee21-467d-9b24-3e666e211e1f",
   "metadata": {},
   "source": [
    "## Data Preview\n",
    "This includes some basic view of the data before processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eee87c20-e092-4c65-b2b8-56f6742f2dbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T08:18:48.923406Z",
     "iopub.status.busy": "2022-12-16T08:18:48.923406Z",
     "iopub.status.idle": "2022-12-16T08:18:51.313400Z",
     "shell.execute_reply": "2022-12-16T08:18:51.312400Z",
     "shell.execute_reply.started": "2022-12-16T08:18:48.923406Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------+--------------------+-----+\n",
      "|Label|               Title| Content|              Answer|  Set|\n",
      "+-----+--------------------+--------+--------------------+-----+\n",
      "|    1|what is the frenc...|    null|Are you talking a...|Train|\n",
      "|    2|Do we realy need ...|    null|When surfaces are...|Train|\n",
      "|    5|How can I save my...|    null|\"Its 9 way to hac...|Train|\n",
      "|    7|I'm trying to fin...|help me.|        tagworld.com|Train|\n",
      "|    7|define Stability ...|    null|A Linear Time Inv...|Train|\n",
      "+-----+--------------------+--------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f042ac05-7a79-40b4-82ca-3c8d33fa61d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T08:18:51.314401Z",
     "iopub.status.busy": "2022-12-16T08:18:51.314401Z",
     "iopub.status.idle": "2022-12-16T08:18:58.471206Z",
     "shell.execute_reply": "2022-12-16T08:18:58.470269Z",
     "shell.execute_reply.started": "2022-12-16T08:18:51.314401Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+--------------------+-----------------------------------+----------------------+------+\n",
      "|summary|            Label|               Title|                            Content|                Answer|   Set|\n",
      "+-------+-----------------+--------------------+-----------------------------------+----------------------+------+\n",
      "|  count|           364615|              364615|                             200607|                357904|364615|\n",
      "|   mean|5.494765711778177|                null|                           Infinity|              Infinity|  null|\n",
      "| stddev|2.872483870744461|                null|                                NaN|                   NaN|  null|\n",
      "|    min|                1|    ! only 4 girls!?|                                  !|  ! - 3 - 7 . Even ...|  Test|\n",
      "|    max|                9|Describe in your...|黙れこのくそやろう\\nむかつくんだ...|혼돈\\nhttp://dictio...| Train|\n",
      "+-------+-----------------+--------------------+-----------------------------------+----------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baa9206-ef31-4de3-b2e0-aec5d148e249",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0883b5f8-d895-470a-9310-1b632abeb35f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:11:29.355690Z",
     "iopub.status.busy": "2022-12-11T15:11:29.354796Z",
     "iopub.status.idle": "2022-12-11T15:11:29.362691Z",
     "shell.execute_reply": "2022-12-11T15:11:29.361689Z",
     "shell.execute_reply.started": "2022-12-11T15:11:29.355690Z"
    },
    "tags": []
   },
   "source": [
    "### Steps to Take\n",
    "- Merge Test and Train\n",
    "- Rename columns\n",
    "- Change data types\n",
    "- Tokenization\n",
    "- Stop Word Removal\n",
    "- NGram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe89d40c-1e5c-4f05-b860-190e90ce6be5",
   "metadata": {},
   "source": [
    "#### Column Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a597a0c-ec63-41b2-8cb1-a3ba11a8b757",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T08:18:58.473507Z",
     "iopub.status.busy": "2022-12-16T08:18:58.473205Z",
     "iopub.status.idle": "2022-12-16T08:18:58.534203Z",
     "shell.execute_reply": "2022-12-16T08:18:58.533259Z",
     "shell.execute_reply.started": "2022-12-16T08:18:58.473507Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35ed22f5-24e9-4f72-a338-d95ec2c0102e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T08:18:58.535203Z",
     "iopub.status.busy": "2022-12-16T08:18:58.535203Z",
     "iopub.status.idle": "2022-12-16T08:18:58.801309Z",
     "shell.execute_reply": "2022-12-16T08:18:58.800700Z",
     "shell.execute_reply.started": "2022-12-16T08:18:58.535203Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|            Document|  Set|Label|\n",
      "+--------------------+-----+-----+\n",
      "|what is the frenc...|Train|    1|\n",
      "|Do we realy need ...|Train|    2|\n",
      "|How can I save my...|Train|    5|\n",
      "|I'm trying to fin...|Train|    7|\n",
      "|define Stability ...|Train|    7|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('Document', concat(df['Title'], df['Content'], df['Answer'])).select(['Document', 'Set', 'Label'])\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12cd0dbb-e291-4474-8ff1-b68c483a7851",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-15T20:18:08.091934Z",
     "iopub.status.busy": "2022-12-15T20:18:08.090934Z",
     "iopub.status.idle": "2022-12-15T20:18:11.456779Z",
     "shell.execute_reply": "2022-12-15T20:18:11.455994Z",
     "shell.execute_reply.started": "2022-12-15T20:18:08.091934Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "before = df.count()\n",
    "before_train = df.filter('Set == \"Train\"').count()\n",
    "before_test = df.filter('Set == \"Test\"').count()\n",
    "df = df.filter('Document is NOT NULL').withColumn('Length', length(df['Document']))\n",
    "after = df.count()\n",
    "after_train = df.filter('Set == \"Train\"').count()\n",
    "after_test = df.filter('Set == \"Test\"').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6b1b6e7-73cf-4b96-bf71-b9348229cf42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-15T20:18:11.458780Z",
     "iopub.status.busy": "2022-12-15T20:18:11.458780Z",
     "iopub.status.idle": "2022-12-15T20:18:12.481216Z",
     "shell.execute_reply": "2022-12-15T20:18:12.480300Z",
     "shell.execute_reply.started": "2022-12-15T20:18:11.458780Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 349605 training samples and 15010 test samples\n",
      "0 rows were dropped, 0 training samples and 0 test samples.\n",
      "There are now 349605 training samples and 15010 test samples\n"
     ]
    }
   ],
   "source": [
    "print(f'''There were {before_train} training samples and {before_test} test samples''')\n",
    "print(f'{before - after} rows were dropped, {before_train - after_train} training samples and {before_test - after_test} test samples.')\n",
    "print(f'''There are now {df.filter('Set == \"Train\"').count()} training samples and {df.filter('Set == \"Test\"').count()} test samples''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2cd1f7-f5f1-4818-8592-be3ae06b18cb",
   "metadata": {},
   "source": [
    "#### Tokenization (Regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8a5091d-2742-4ae8-92c3-f9486967f37d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-15T20:18:12.483216Z",
     "iopub.status.busy": "2022-12-15T20:18:12.482216Z",
     "iopub.status.idle": "2022-12-15T20:18:13.067742Z",
     "shell.execute_reply": "2022-12-15T20:18:13.066745Z",
     "shell.execute_reply.started": "2022-12-15T20:18:12.483216Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------+\n",
      "|                                                                                              Tokens|\n",
      "+----------------------------------------------------------------------------------------------------+\n",
      "|               [what, is, the, french, name, for, arm, cover, are, you, talking, about, a, gauntlet]|\n",
      "|[do, we, realy, need, oil, to, run, machines, when, surfaces, are, rubbed, against, each, other, ...|\n",
      "|[how, can, i, save, my, yahoo, id, to, the, hackers, tell, me, please, how, the, hacker, attack, ...|\n",
      "|[i, m, trying, to, find, the, url, for, this, website, similar, to, myspace, called, tag, how, do...|\n",
      "|[define, stability, of, linear, time, invariant, systems, a, linear, time, invariant, system, lti...|\n",
      "+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regex_tokenizer = RegexTokenizer(inputCol='Document', outputCol='Tokens', pattern='\\\\W')\n",
    "\n",
    "df_regex_token = regex_tokenizer.transform(df)\n",
    "\n",
    "df_regex_token.select('Tokens').show(5, truncate=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf77a77a-d338-4f09-97a5-83eb6fa2f5a2",
   "metadata": {},
   "source": [
    "#### Stop Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "538affdc-7481-4378-8913-d752a76406d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-15T20:18:13.069746Z",
     "iopub.status.busy": "2022-12-15T20:18:13.069746Z",
     "iopub.status.idle": "2022-12-15T20:18:13.460884Z",
     "shell.execute_reply": "2022-12-15T20:18:13.459883Z",
     "shell.execute_reply.started": "2022-12-15T20:18:13.069746Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------+-------------------------------------------------------+\n",
      "|                                               Document|                                             StopTokens|\n",
      "+-------------------------------------------------------+-------------------------------------------------------+\n",
      "|what is the french name for arm cover?Are you talkin...|          [french, name, arm, cover, talking, gauntlet]|\n",
      "|Do we realy need Oil to run machines?When surfaces a...|[realy, need, oil, run, machines, surfaces, rubbed, ...|\n",
      "|How can I save my yahoo id to the hackers?Tell me pl...|[save, yahoo, id, hackers, tell, please, hacker, att...|\n",
      "|I'm trying to find the Url for this website similar ...|[m, trying, find, url, website, similar, myspace, ca...|\n",
      "|define Stability of Linear Time-Invariant Systems?A ...|[define, stability, linear, time, invariant, systems...|\n",
      "+-------------------------------------------------------+-------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remover = StopWordsRemover(inputCol=\"Tokens\", outputCol=\"StopTokens\")\n",
    "df_removed = remover.transform(df_regex_token)\n",
    "df_removed.select(['Document', 'StopTokens']).show(5,truncate=55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bff9695-12dc-4e1e-8b4c-aab6c9ba626e",
   "metadata": {},
   "source": [
    "#### NGrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2419a513-2598-4be4-85ec-bc2f53fe02e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-15T20:18:13.466886Z",
     "iopub.status.busy": "2022-12-15T20:18:13.465956Z",
     "iopub.status.idle": "2022-12-15T20:18:13.682017Z",
     "shell.execute_reply": "2022-12-15T20:18:13.681017Z",
     "shell.execute_reply.started": "2022-12-15T20:18:13.466886Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------+-------------------------------------------------------+\n",
      "|                                               Document|                                                 NGrams|\n",
      "+-------------------------------------------------------+-------------------------------------------------------+\n",
      "|what is the french name for arm cover?Are you talkin...|[what is, is the, the french, french name, name for,...|\n",
      "|Do we realy need Oil to run machines?When surfaces a...|[do we, we realy, realy need, need oil, oil to, to r...|\n",
      "|How can I save my yahoo id to the hackers?Tell me pl...|[how can, can i, i save, save my, my yahoo, yahoo id...|\n",
      "|I'm trying to find the Url for this website similar ...|[i m, m trying, trying to, to find, find the, the ur...|\n",
      "|define Stability of Linear Time-Invariant Systems?A ...|[define stability, stability of, of linear, linear t...|\n",
      "+-------------------------------------------------------+-------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngram = NGram(n=2, inputCol=\"Tokens\", outputCol=\"NGrams\")\n",
    "\n",
    "df_ngrams = ngram.transform(df_removed)\n",
    "\n",
    "df_ngrams.select(['Document', 'NGrams']).show(5,truncate=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f3aba4e-4dea-4ea9-be9a-b065e5b9818e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-15T20:18:13.685018Z",
     "iopub.status.busy": "2022-12-15T20:18:13.685018Z",
     "iopub.status.idle": "2022-12-15T20:18:13.951265Z",
     "shell.execute_reply": "2022-12-15T20:18:13.950001Z",
     "shell.execute_reply.started": "2022-12-15T20:18:13.685018Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------+-------------------------------------------------------+\n",
      "|                                               Document|                                             StopNGrams|\n",
      "+-------------------------------------------------------+-------------------------------------------------------+\n",
      "|what is the french name for arm cover?Are you talkin...|[what is, is the, the french, french name, name for,...|\n",
      "|Do we realy need Oil to run machines?When surfaces a...|[do we, we realy, realy need, need oil, oil to, to r...|\n",
      "|How can I save my yahoo id to the hackers?Tell me pl...|[how can, can i, i save, save my, my yahoo, yahoo id...|\n",
      "|I'm trying to find the Url for this website similar ...|[i m, m trying, trying to, to find, find the, the ur...|\n",
      "|define Stability of Linear Time-Invariant Systems?A ...|[define stability, stability of, of linear, linear t...|\n",
      "+-------------------------------------------------------+-------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remover = StopWordsRemover(inputCol=\"NGrams\", outputCol=\"StopNGrams\")\n",
    "df_removed = remover.transform(df_ngrams)\n",
    "df_removed.select(['Document', 'StopNGrams']).show(5,truncate=55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dc6dc0-f17d-40a7-9dbd-b536aa15b91f",
   "metadata": {},
   "source": [
    "### Full Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa9d170d-374b-4f30-9aea-c43279fa49f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T08:45:59.858395Z",
     "iopub.status.busy": "2022-12-16T08:45:59.858329Z",
     "iopub.status.idle": "2022-12-16T08:45:59.867398Z",
     "shell.execute_reply": "2022-12-16T08:45:59.866438Z",
     "shell.execute_reply.started": "2022-12-16T08:45:59.858395Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 2\n",
      "2000 6\n",
      "2000 10\n",
      "2000 14\n",
      "3000 2\n",
      "3000 6\n",
      "3000 10\n",
      "3000 14\n",
      "4000 2\n",
      "4000 6\n",
      "4000 10\n",
      "4000 14\n",
      "5000 2\n",
      "5000 6\n",
      "5000 10\n",
      "5000 14\n",
      "6000 2\n",
      "6000 6\n",
      "6000 10\n",
      "6000 14\n"
     ]
    }
   ],
   "source": [
    "for numFeatures in range(2000,6001, 1000):\n",
    "    for minDocFreq in range(2,16,4):\n",
    "        print(numFeatures, minDocFreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47b07cc-bc3c-45ea-982e-435b150d91de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T08:56:14.469016Z",
     "iopub.status.busy": "2022-12-16T08:56:14.469016Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema_results = StructType([ \\\n",
    "    StructField(\"FeatureLength\",IntegerType(),True), \\\n",
    "    StructField(\"MinimumDocumentFrequency\",IntegerType(),True), \\\n",
    "    StructField(\"Accuracy\", StringType(), True)\\\n",
    "  ])\n",
    "\n",
    "df_results = spark.createDataFrame(data=[(None,None,None)], schema=schema_results)\n",
    "\n",
    "reg_tokenizer = RegexTokenizer(inputCol='Document', outputCol='Tokens', pattern='\\\\W')\n",
    "stop_word_remover = StopWordsRemover(inputCol='Tokens', outputCol='StopTokens')\n",
    "string_indexer = StringIndexer(inputCol='Label', outputCol='LabelString')\n",
    "svm = LinearSVC()\n",
    "ovr = OneVsRest(classifier=svm, featuresCol='TF-IDF', labelCol='LabelString')\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='LabelString')\n",
    "\n",
    "for numFeatures in range(2000,6001,1000):\n",
    "    for minDocFreq in range(2,16,4):\n",
    "        tf = HashingTF(inputCol='StopTokens', outputCol='CountVec', numFeatures=numFeatures)\n",
    "        idf = IDF(inputCol='CountVec', outputCol='TF-IDF', minDocFreq=minDocFreq)\n",
    "\n",
    "        # Putting pipeline together\n",
    "        pipeline = Pipeline(stages=[\n",
    "            reg_tokenizer,\n",
    "            stop_word_remover,\n",
    "            tf,\n",
    "            idf,\n",
    "            string_indexer,\n",
    "        ])\n",
    "\n",
    "        # Training and fitting\n",
    "        pipeline = pipeline.fit(df)\n",
    "        df_processed = pipeline.transform(df)\n",
    "\n",
    "        df_train = df_processed.filter('Set == \"Train\"').select('TF-IDF', 'LabelString')\n",
    "        df_test = df_processed.filter('Set == \"Test\"').select('TF-IDF', 'LabelString')\n",
    "\n",
    "        ovrModel = ovr.fit(df_train)\n",
    "        predictions = ovrModel.transform(df_test)\n",
    "\n",
    "        accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "        vals = [(numFeatures, minDocFreq, accuracy)]\n",
    "        new_row = spark.createDataFrame(data=vals, schema=schema_results)\n",
    "        df_results = df_results.union(new_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fe095be-5bb9-4531-b42b-53366fae9688",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T08:32:06.843025Z",
     "iopub.status.busy": "2022-12-16T08:32:06.842026Z",
     "iopub.status.idle": "2022-12-16T08:32:12.461397Z",
     "shell.execute_reply": "2022-12-16T08:32:12.460504Z",
     "shell.execute_reply.started": "2022-12-16T08:32:06.843025Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Function: string (nullable = true)\n",
      " |-- FeatureLength: string (nullable = true)\n",
      " |-- Train: string (nullable = true)\n",
      " |-- Test: string (nullable = true)\n",
      " |-- Accuracy: string (nullable = true)\n",
      "\n",
      "+---------------+-------------+------+-----+--------+\n",
      "|Function       |FeatureLength|Train |Test |Accuracy|\n",
      "+---------------+-------------+------+-----+--------+\n",
      "|CountVectoriser|262000       |100   |10   |0.514   |\n",
      "|HashingTF      |10           |350000|15000|0.105   |\n",
      "|HashingTF      |100          |350000|15000|0.248   |\n",
      "|HashingTF      |1000         |350000|15000|0.509   |\n",
      "+---------------+-------------+------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [,\n",
    "    (\"HashingTF\",10,350000, 15000,0.105),\n",
    "    (\"HashingTF\",100,350000, 15000,0.248),\n",
    "    ('HashingTF', 1000, 350000, 15000, 0.509)\n",
    "  ]\n",
    "\n",
    "schema = StructType([ \\\n",
    "    StructField(\"Function\",StringType(),True), \\\n",
    "    StructField(\"FeatureLength\",StringType(),True), \\\n",
    "    StructField(\"Train\",StringType(),True), \\\n",
    "    StructField(\"Test\", StringType(), True), \\\n",
    "    StructField(\"Accuracy\", StringType(), True)\\\n",
    "  ])\n",
    " \n",
    "df_results = spark.createDataFrame(schema=schema)\n",
    "df_results.printSchema()\n",
    "df_results.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "691d23ad-288f-4e64-967a-573a6923d6b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T08:31:26.007338Z",
     "iopub.status.busy": "2022-12-16T08:31:26.006341Z",
     "iopub.status.idle": "2022-12-16T08:31:26.075336Z",
     "shell.execute_reply": "2022-12-16T08:31:26.074337Z",
     "shell.execute_reply.started": "2022-12-16T08:31:26.007338Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vals = [(\"CountVectoriser\",262000,100, 10,0.514)]\n",
    "schema = StructType([ \\\n",
    "    StructField(\"Function\",StringType(),True), \\\n",
    "    StructField(\"FeatureLength\",StringType(),True), \\\n",
    "    StructField(\"Train\",StringType(),True), \\\n",
    "    StructField(\"Test\", StringType(), True), \\\n",
    "    StructField(\"Accuracy\", StringType(), True)\\\n",
    "  ])\n",
    "new_rows = spark.createDataFrame(data=vals,schema=schema)\n",
    "df_results = df_results.union(new_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "085816a4-ce57-4f87-a6a7-fc38ffb3f1ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T08:31:32.825622Z",
     "iopub.status.busy": "2022-12-16T08:31:32.825622Z",
     "iopub.status.idle": "2022-12-16T08:31:43.711863Z",
     "shell.execute_reply": "2022-12-16T08:31:43.710859Z",
     "shell.execute_reply.started": "2022-12-16T08:31:32.825622Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+------+-----+--------+\n",
      "|       Function|FeatureLength| Train| Test|Accuracy|\n",
      "+---------------+-------------+------+-----+--------+\n",
      "|CountVectoriser|       262000|   100|   10|   0.514|\n",
      "|      HashingTF|           10|350000|15000|   0.105|\n",
      "|      HashingTF|          100|350000|15000|   0.248|\n",
      "|      HashingTF|         1000|350000|15000|   0.509|\n",
      "|CountVectoriser|       262000|   100|   10|   0.514|\n",
      "+---------------+-------------+------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_results.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "8a1524db6d30cecd9499819b2838fc928f01903195772e5788511080a339eb2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
